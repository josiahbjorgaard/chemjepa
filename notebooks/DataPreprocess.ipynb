{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "587673f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7cae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654a361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2681742 ,  0.        , -0.38007   , ..., -0.5604895 ,\n",
       "         0.41710252, -0.08229849],\n",
       "       [-0.2681742 ,  0.        , -0.38007   , ..., -0.5604895 ,\n",
       "         0.41710252, -0.08229849],\n",
       "       [-0.2681742 ,  0.        , -0.38007   , ..., -0.5604895 ,\n",
       "         0.41710252, -0.08229849],\n",
       "       ...,\n",
       "       [ 0.33149236,  0.        , -0.24462274, ..., -0.32275528,\n",
       "         0.08757384,  0.6201978 ],\n",
       "       [ 0.33149236,  0.        , -0.24462274, ..., -0.32275528,\n",
       "         0.08757384,  0.6201978 ],\n",
       "       [ 0.33149236,  0.        , -0.24462274, ..., -0.32275528,\n",
       "         0.08757384,  0.6201978 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('../data/pad_false/train_sm_name.npy', allow_pickle=True)\n",
    "np.load('../data/pad_false/train_ChemBERTa_v2_77MTR_cls_pad_False.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "900126be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-29 21:38:13--  https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/pubchem_10m.txt.zip\n",
      "Resolving deepchemdata.s3-us-west-1.amazonaws.com (deepchemdata.s3-us-west-1.amazonaws.com)... 52.219.113.162, 52.219.220.178, 52.219.193.26, ...\n",
      "Connecting to deepchemdata.s3-us-west-1.amazonaws.com (deepchemdata.s3-us-west-1.amazonaws.com)|52.219.113.162|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 130376753 (124M) [application/zip]\n",
      "Saving to: ‘pubchem_10m.txt.zip.1’\n",
      "\n",
      "pubchem_10m.txt.zip 100%[===================>] 124.34M  73.1MB/s    in 1.7s    \n",
      "\n",
      "2024-04-29 21:38:15 (73.1 MB/s) - ‘pubchem_10m.txt.zip.1’ saved [130376753/130376753]\n",
      "\n",
      "Archive:  pubchem_10m.txt.zip\n",
      "  inflating: pubchem-10m.txt         \n"
     ]
    }
   ],
   "source": [
    "!wget https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/pubchem_10m.txt.zip\n",
    "!unzip pubchem_10m.txt.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46261eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pubchem-10m.txt\", \"r\") as grilled_cheese:\n",
    "    lines = grilled_cheese.readlines()\n",
    "lines = [l.rstrip(\"\\n\") for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e8fd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'SMILES':lines})\n",
    "df['Count'] = df['SMILES'].str.len()\n",
    "df=df[df.Count < 126]\n",
    "df = df[df.Count > 12]\n",
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d6d331a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.Count.hist(bins=100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53086b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import collections\n",
    "import os\n",
    "import re\n",
    "import importlib.resources\n",
    "from typing import List, Optional\n",
    "from transformers import BertTokenizer\n",
    "from logging import getLogger\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "\"\"\"\n",
    "SMI_REGEX_PATTERN: str\n",
    "SMILES regex pattern for tokenization. Designed by Schwaller et. al.\n",
    "\n",
    "References\n",
    "----------\n",
    ".. [1]  Philippe Schwaller, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A. Hunter, Costas Bekas, and Alpha A. Lee\n",
    "ACS Central Science 2019 5 (9): Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction\n",
    "1572-1583 DOI: 10.1021/acscentsci.9b00576\n",
    "\"\"\"\n",
    "\n",
    "SMI_REGEX_PATTERN = r\"\"\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\|\\/|:|~|@|\\?|>>?|\\*|\\$|\\%[0-9]{2}|[0-9])\"\"\"\n",
    "\n",
    "# add vocab_file dict\n",
    "VOCAB_FILES_NAMES = {\"vocab_file\": \"vocab.txt\"}\n",
    "def load_vocab(vocab_file):\n",
    "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "    vocab = collections.OrderedDict()\n",
    "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
    "        tokens = reader.readlines()\n",
    "    for index, token in enumerate(tokens):\n",
    "        token = token.rstrip(\"\\n\")\n",
    "        vocab[token] = index\n",
    "    return vocab\n",
    "class BasicSmilesTokenizer(object):\n",
    "    \"\"\"\n",
    "    Run basic SMILES tokenization using a regex pattern developed by Schwaller et. al.\n",
    "    This tokenizer is to be used when a tokenizer that does not require the transformers library by HuggingFace is required.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from deepchem.feat.smiles_tokenizer import BasicSmilesTokenizer\n",
    "    >>> tokenizer = BasicSmilesTokenizer()\n",
    "    >>> print(tokenizer.tokenize(\"CC(=O)OC1=CC=CC=C1C(=O)O\"))\n",
    "    ['C', 'C', '(', '=', 'O', ')', 'O', 'C', '1', '=', 'C', 'C', '=', 'C', 'C', '=', 'C', '1', 'C', '(', '=', 'O', ')', 'O']\n",
    "\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Philippe Schwaller, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A. Hunter, Costas Bekas, and Alpha A. Lee\n",
    "        ACS Central Science 2019 5 (9): Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction\n",
    "        1572-1583 DOI: 10.1021/acscentsci.9b00576\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, regex_pattern: str = SMI_REGEX_PATTERN):\n",
    "        \"\"\"Constructs a BasicSMILESTokenizer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        regex: string\n",
    "            SMILES token regex\n",
    "        \"\"\"\n",
    "        self.regex_pattern = regex_pattern\n",
    "        self.regex = re.compile(self.regex_pattern)\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Basic Tokenization of a SMILES.\n",
    "        \"\"\"\n",
    "        tokens = [token for token in self.regex.findall(text)]\n",
    "        return tokens\n",
    "\n",
    "class SmilesTokenizer(BertTokenizer):\n",
    "    \"\"\"\n",
    "    Creates the SmilesTokenizer class. The tokenizer heavily inherits from the BertTokenizer\n",
    "    implementation found in Huggingface's transformers library. It runs a WordPiece tokenization\n",
    "    algorithm over SMILES strings using the tokenisation SMILES regex developed by Schwaller et. al.\n",
    "\n",
    "    Please see https://github.com/huggingface/transformers\n",
    "    and https://github.com/rxn4chemistry/rxnfp for more details.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from deepchem.feat.smiles_tokenizer import SmilesTokenizer\n",
    "    >>> current_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "    >>> vocab_path = os.path.join(current_dir, 'tests/data', 'vocab.txt')\n",
    "    >>> tokenizer = SmilesTokenizer(vocab_path)\n",
    "    >>> print(tokenizer.encode(\"CC(=O)OC1=CC=CC=C1C(=O)O\"))\n",
    "    [12, 16, 16, 17, 22, 19, 18, 19, 16, 20, 22, 16, 16, 22, 16, 16, 22, 16, 20, 16, 17, 22, 19, 18, 19, 13]\n",
    "\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Schwaller, Philippe; Probst, Daniel; Vaucher, Alain C.; Nair, Vishnu H; Kreutter, David;\n",
    "        Laino, Teodoro; et al. (2019): Mapping the Space of Chemical Reactions using Attention-Based Neural\n",
    "        Networks. ChemRxiv. Preprint. https://doi.org/10.26434/chemrxiv.9897365.v3\n",
    "\n",
    "    Note\n",
    "    ----\n",
    "    This class requires huggingface's transformers and tokenizers libraries to be installed.\n",
    "    \"\"\"\n",
    "    #vocab_files_names = VOCAB_FILES_NAMES\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_file: str = '',\n",
    "        # unk_token=\"[UNK]\",\n",
    "        # sep_token=\"[SEP]\",\n",
    "        # pad_token=\"[PAD]\",\n",
    "        # cls_token=\"[CLS]\",\n",
    "        # mask_token=\"[MASK]\",\n",
    "        **kwargs):\n",
    "        \"\"\"Constructs a SmilesTokenizer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vocab_file: str\n",
    "            Path to a SMILES character per line vocabulary file.\n",
    "            Default vocab file is found in deepchem/feat/tests/data/vocab.txt\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(vocab_file, **kwargs)\n",
    "\n",
    "        if not os.path.isfile(vocab_file):\n",
    "            raise ValueError(\n",
    "                \"Can't find a vocab file at path '{}'.\".format(vocab_file))\n",
    "        self.vocab = load_vocab(vocab_file)\n",
    "        self.highest_unused_index = max([\n",
    "            i for i, v in enumerate(self.vocab.keys())\n",
    "            if v.startswith(\"[unused\")\n",
    "        ])\n",
    "        self.ids_to_tokens = collections.OrderedDict([\n",
    "            (ids, tok) for tok, ids in self.vocab.items()\n",
    "        ])\n",
    "        self.basic_tokenizer = BasicSmilesTokenizer()\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab)\n",
    "\n",
    "    @property\n",
    "    def vocab_list(self):\n",
    "        return list(self.vocab.keys())\n",
    "\n",
    "    def _tokenize(self, text: str, max_seq_length: int = 512, **kwargs):\n",
    "        \"\"\"Tokenize a string into a list of tokens.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: str\n",
    "            Input string sequence to be tokenized.\n",
    "        \"\"\"\n",
    "\n",
    "        max_len_single_sentence = max_seq_length - 2\n",
    "        split_tokens = [\n",
    "            token for token in self.basic_tokenizer.tokenize(text)\n",
    "            [:max_len_single_sentence]\n",
    "        ]\n",
    "        return split_tokens\n",
    "\n",
    "    def _convert_token_to_id(self, token: str):\n",
    "        \"\"\"Converts a token (str/unicode) in an id using the vocab.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        token: str\n",
    "            String token from a larger sequence to be converted to a numerical id.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.vocab.get(token, self.vocab.get(self.unk_token))\n",
    "\n",
    "    def _convert_id_to_token(self, index: int):\n",
    "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index: int\n",
    "            Integer index to be converted back to a string-based token as part of a larger sequence.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.ids_to_tokens.get(index, self.unk_token)\n",
    "\n",
    "    def convert_tokens_to_string(self, tokens: List[str]):\n",
    "        \"\"\"Converts a sequence of tokens (string) in a single string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens: List[str]\n",
    "            List of tokens for a given string sequence.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out_string: str\n",
    "            Single string from combined tokens.\n",
    "        \"\"\"\n",
    "\n",
    "        out_string: str = \" \".join(tokens).replace(\" ##\", \"\").strip()\n",
    "        return out_string\n",
    "\n",
    "    def add_special_tokens_ids_single_sequence(self,\n",
    "                                               token_ids: List[Optional[int]]):\n",
    "        \"\"\"Adds special tokens to the a sequence for sequence classification tasks.\n",
    "\n",
    "        A BERT sequence has the following format: [CLS] X [SEP]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        token_ids: list[int]\n",
    "            list of tokenized input ids. Can be obtained using the encode or encode_plus methods.\n",
    "        \"\"\"\n",
    "\n",
    "        return [self.cls_token_id] + token_ids + [self.sep_token_id]\n",
    "\n",
    "    def add_special_tokens_single_sequence(self, tokens: List[str]):\n",
    "        \"\"\"Adds special tokens to the a sequence for sequence classification tasks.\n",
    "        A BERT sequence has the following format: [CLS] X [SEP]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens: List[str]\n",
    "            List of tokens for a given string sequence.\n",
    "        \"\"\"\n",
    "        return [self.cls_token] + tokens + [self.sep_token]\n",
    "\n",
    "    def add_special_tokens_ids_sequence_pair(\n",
    "            self, token_ids_0: List[Optional[int]],\n",
    "            token_ids_1: List[Optional[int]]) -> List[Optional[int]]:\n",
    "        \"\"\"Adds special tokens to a sequence pair for sequence classification tasks.\n",
    "        A BERT sequence pair has the following format: [CLS] A [SEP] B [SEP]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        token_ids_0: List[int]\n",
    "            List of ids for the first string sequence in the sequence pair (A).\n",
    "        token_ids_1: List[int]\n",
    "            List of tokens for the second string sequence in the sequence pair (B).\n",
    "        \"\"\"\n",
    "\n",
    "        sep = [self.sep_token_id]\n",
    "        cls = [self.cls_token_id]\n",
    "\n",
    "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
    "\n",
    "    def add_padding_tokens(self,\n",
    "                           token_ids: List[Optional[int]],\n",
    "                           length: int,\n",
    "                           right: bool = True) -> List[Optional[int]]:\n",
    "        \"\"\"Adds padding tokens to return a sequence of length max_length.\n",
    "        By default padding tokens are added to the right of the sequence.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        token_ids: list[optional[int]]\n",
    "            list of tokenized input ids. Can be obtained using the encode or encode_plus methods.\n",
    "        length: int\n",
    "            TODO\n",
    "        right: bool, default True\n",
    "            TODO\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[int]\n",
    "            TODO\n",
    "        \"\"\"\n",
    "        padding = [self.pad_token_id] * (length - len(token_ids))\n",
    "\n",
    "        if right:\n",
    "            return token_ids + padding\n",
    "        else:\n",
    "            return padding + token_ids\n",
    "\n",
    "    def save_vocabulary(\n",
    "        self,\n",
    "        save_directory: str,\n",
    "        filename_prefix: Optional[str] = None\n",
    "    ):  # -> Tuple[str]: doctest issue raised with this return type annotation\n",
    "        \"\"\"Save the tokenizer vocabulary to a file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vocab_path: obj: str\n",
    "            The directory in which to save the SMILES character per line vocabulary file.\n",
    "            Default vocab file is found in deepchem/feat/tests/data/vocab.txt\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        vocab_file: Tuple\n",
    "            Paths to the files saved.\n",
    "            typle with string to a SMILES character per line vocabulary file.\n",
    "            Default vocab file is found in deepchem/feat/tests/data/vocab.txt\n",
    "        \"\"\"\n",
    "        index = 0\n",
    "        if os.path.isdir(save_directory):\n",
    "            vocab_file = os.path.join(save_directory,\n",
    "                                      VOCAB_FILES_NAMES[\"vocab_file\"])\n",
    "        else:\n",
    "            vocab_file = save_directory\n",
    "        with open(vocab_file, \"w\", encoding=\"utf-8\") as writer:\n",
    "            for token, token_index in sorted(self.vocab.items(),\n",
    "                                             key=lambda kv: kv[1]):\n",
    "                if index != token_index:\n",
    "                    logger.warning(\n",
    "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
    "                        \" Please check that the vocabulary is not corrupted!\".\n",
    "                        format(vocab_file))\n",
    "                    index = token_index\n",
    "                writer.write(token + \"\\n\")\n",
    "                index += 1\n",
    "        return (vocab_file,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b82e8dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [12, 16, 16, 17, 11, 18, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=SmilesTokenizer('../data/vocab.txt')\n",
    "tokenizer('CCH([Mg100])', max_length=256, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d87a63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['SMILES'],\n",
       "    num_rows: 10000000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.rename_column('0','SMILES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea8aaace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('[PAD]', 0),\n",
       "             ('[unused1]', 1),\n",
       "             ('[unused2]', 2),\n",
       "             ('[unused3]', 3),\n",
       "             ('[unused4]', 4),\n",
       "             ('[unused5]', 5),\n",
       "             ('[unused6]', 6),\n",
       "             ('[unused7]', 7),\n",
       "             ('[unused8]', 8),\n",
       "             ('[unused9]', 9),\n",
       "             ('[unused10]', 10),\n",
       "             ('[UNK]', 11),\n",
       "             ('[CLS]', 12),\n",
       "             ('[SEP]', 13),\n",
       "             ('[MASK]', 14),\n",
       "             ('c', 15),\n",
       "             ('C', 16),\n",
       "             ('(', 17),\n",
       "             (')', 18),\n",
       "             ('O', 19),\n",
       "             ('1', 20),\n",
       "             ('2', 21),\n",
       "             ('=', 22),\n",
       "             ('N', 23),\n",
       "             ('.', 24),\n",
       "             ('n', 25),\n",
       "             ('3', 26),\n",
       "             ('F', 27),\n",
       "             ('Cl', 28),\n",
       "             ('>>', 29),\n",
       "             ('~', 30),\n",
       "             ('-', 31),\n",
       "             ('4', 32),\n",
       "             ('[C@H]', 33),\n",
       "             ('S', 34),\n",
       "             ('[C@@H]', 35),\n",
       "             ('[O-]', 36),\n",
       "             ('Br', 37),\n",
       "             ('#', 38),\n",
       "             ('/', 39),\n",
       "             ('[nH]', 40),\n",
       "             ('[N+]', 41),\n",
       "             ('s', 42),\n",
       "             ('5', 43),\n",
       "             ('o', 44),\n",
       "             ('P', 45),\n",
       "             ('[Na+]', 46),\n",
       "             ('[Si]', 47),\n",
       "             ('I', 48),\n",
       "             ('[Na]', 49),\n",
       "             ('[Pd]', 50),\n",
       "             ('[K+]', 51),\n",
       "             ('[K]', 52),\n",
       "             ('[P]', 53),\n",
       "             ('B', 54),\n",
       "             ('[C@]', 55),\n",
       "             ('[C@@]', 56),\n",
       "             ('[Cl-]', 57),\n",
       "             ('6', 58),\n",
       "             ('[OH-]', 59),\n",
       "             ('\\\\', 60),\n",
       "             ('[N-]', 61),\n",
       "             ('[Li]', 62),\n",
       "             ('[H]', 63),\n",
       "             ('[2H]', 64),\n",
       "             ('[NH4+]', 65),\n",
       "             ('[c-]', 66),\n",
       "             ('[P-]', 67),\n",
       "             ('[Cs+]', 68),\n",
       "             ('[Li+]', 69),\n",
       "             ('[Cs]', 70),\n",
       "             ('[NaH]', 71),\n",
       "             ('[H-]', 72),\n",
       "             ('[O+]', 73),\n",
       "             ('[BH4-]', 74),\n",
       "             ('[Cu]', 75),\n",
       "             ('7', 76),\n",
       "             ('[Mg]', 77),\n",
       "             ('[Fe+2]', 78),\n",
       "             ('[n+]', 79),\n",
       "             ('[Sn]', 80),\n",
       "             ('[BH-]', 81),\n",
       "             ('[Pd+2]', 82),\n",
       "             ('[CH]', 83),\n",
       "             ('[I-]', 84),\n",
       "             ('[Br-]', 85),\n",
       "             ('[C-]', 86),\n",
       "             ('[Zn]', 87),\n",
       "             ('[B-]', 88),\n",
       "             ('[F-]', 89),\n",
       "             ('[Al]', 90),\n",
       "             ('[P+]', 91),\n",
       "             ('[BH3-]', 92),\n",
       "             ('[Fe]', 93),\n",
       "             ('[C]', 94),\n",
       "             ('[AlH4]', 95),\n",
       "             ('[Ni]', 96),\n",
       "             ('[SiH]', 97),\n",
       "             ('8', 98),\n",
       "             ('[Cu+2]', 99),\n",
       "             ('[Mn]', 100),\n",
       "             ('[AlH]', 101),\n",
       "             ('[nH+]', 102),\n",
       "             ('[AlH4-]', 103),\n",
       "             ('[O-2]', 104),\n",
       "             ('[Cr]', 105),\n",
       "             ('[Mg+2]', 106),\n",
       "             ('[NH3+]', 107),\n",
       "             ('[S@]', 108),\n",
       "             ('[Pt]', 109),\n",
       "             ('[Al+3]', 110),\n",
       "             ('[S@@]', 111),\n",
       "             ('[S-]', 112),\n",
       "             ('[Ti]', 113),\n",
       "             ('[Zn+2]', 114),\n",
       "             ('[PH]', 115),\n",
       "             ('[NH2+]', 116),\n",
       "             ('[Ru]', 117),\n",
       "             ('[Ag+]', 118),\n",
       "             ('[S+]', 119),\n",
       "             ('[I+3]', 120),\n",
       "             ('[NH+]', 121),\n",
       "             ('[Ca+2]', 122),\n",
       "             ('[Ag]', 123),\n",
       "             ('9', 124),\n",
       "             ('[Os]', 125),\n",
       "             ('[Se]', 126),\n",
       "             ('[SiH2]', 127),\n",
       "             ('[Ca]', 128),\n",
       "             ('[Ti+4]', 129),\n",
       "             ('[Ac]', 130),\n",
       "             ('[Cu+]', 131),\n",
       "             ('[S]', 132),\n",
       "             ('[Rh]', 133),\n",
       "             ('[Cl+3]', 134),\n",
       "             ('[cH-]', 135),\n",
       "             ('[Zn+]', 136),\n",
       "             ('[O]', 137),\n",
       "             ('[Cl+]', 138),\n",
       "             ('[SH]', 139),\n",
       "             ('[H+]', 140),\n",
       "             ('[Pd+]', 141),\n",
       "             ('[se]', 142),\n",
       "             ('[PH+]', 143),\n",
       "             ('[I]', 144),\n",
       "             ('[Pt+2]', 145),\n",
       "             ('[C+]', 146),\n",
       "             ('[Mg+]', 147),\n",
       "             ('[Hg]', 148),\n",
       "             ('[W]', 149),\n",
       "             ('[SnH]', 150),\n",
       "             ('[SiH3]', 151),\n",
       "             ('[Fe+3]', 152),\n",
       "             ('[NH]', 153),\n",
       "             ('[Mo]', 154),\n",
       "             ('[CH2+]', 155),\n",
       "             ('%10', 156),\n",
       "             ('[CH2-]', 157),\n",
       "             ('[CH2]', 158),\n",
       "             ('[n-]', 159),\n",
       "             ('[Ce+4]', 160),\n",
       "             ('[NH-]', 161),\n",
       "             ('[Co]', 162),\n",
       "             ('[I+]', 163),\n",
       "             ('[PH2]', 164),\n",
       "             ('[Pt+4]', 165),\n",
       "             ('[Ce]', 166),\n",
       "             ('[B]', 167),\n",
       "             ('[Sn+2]', 168),\n",
       "             ('[Ba+2]', 169),\n",
       "             ('%11', 170),\n",
       "             ('[Fe-3]', 171),\n",
       "             ('[18F]', 172),\n",
       "             ('[SH-]', 173),\n",
       "             ('[Pb+2]', 174),\n",
       "             ('[Os-2]', 175),\n",
       "             ('[Zr+4]', 176),\n",
       "             ('[N]', 177),\n",
       "             ('[Ir]', 178),\n",
       "             ('[Bi]', 179),\n",
       "             ('[Ni+2]', 180),\n",
       "             ('[P@]', 181),\n",
       "             ('[Co+2]', 182),\n",
       "             ('[s+]', 183),\n",
       "             ('[As]', 184),\n",
       "             ('[P+3]', 185),\n",
       "             ('[Hg+2]', 186),\n",
       "             ('[Yb+3]', 187),\n",
       "             ('[CH-]', 188),\n",
       "             ('[Zr+2]', 189),\n",
       "             ('[Mn+2]', 190),\n",
       "             ('[CH+]', 191),\n",
       "             ('[In]', 192),\n",
       "             ('[KH]', 193),\n",
       "             ('[Ce+3]', 194),\n",
       "             ('[Zr]', 195),\n",
       "             ('[AlH2-]', 196),\n",
       "             ('[OH2+]', 197),\n",
       "             ('[Ti+3]', 198),\n",
       "             ('[Rh+2]', 199),\n",
       "             ('[Sb]', 200),\n",
       "             ('[S-2]', 201),\n",
       "             ('%12', 202),\n",
       "             ('[P@@]', 203),\n",
       "             ('[Si@H]', 204),\n",
       "             ('[Mn+4]', 205),\n",
       "             ('p', 206),\n",
       "             ('[Ba]', 207),\n",
       "             ('[NH2-]', 208),\n",
       "             ('[Ge]', 209),\n",
       "             ('[Pb+4]', 210),\n",
       "             ('[Cr+3]', 211),\n",
       "             ('[Au]', 212),\n",
       "             ('[LiH]', 213),\n",
       "             ('[Sc+3]', 214),\n",
       "             ('[o+]', 215),\n",
       "             ('[Rh-3]', 216),\n",
       "             ('%13', 217),\n",
       "             ('[Br]', 218),\n",
       "             ('[Sb-]', 219),\n",
       "             ('[S@+]', 220),\n",
       "             ('[I+2]', 221),\n",
       "             ('[Ar]', 222),\n",
       "             ('[V]', 223),\n",
       "             ('[Cu-]', 224),\n",
       "             ('[Al-]', 225),\n",
       "             ('[Te]', 226),\n",
       "             ('[13c]', 227),\n",
       "             ('[13C]', 228),\n",
       "             ('[Cl]', 229),\n",
       "             ('[PH4+]', 230),\n",
       "             ('[SiH4]', 231),\n",
       "             ('[te]', 232),\n",
       "             ('[CH3-]', 233),\n",
       "             ('[S@@+]', 234),\n",
       "             ('[Rh+3]', 235),\n",
       "             ('[SH+]', 236),\n",
       "             ('[Bi+3]', 237),\n",
       "             ('[Br+2]', 238),\n",
       "             ('[La]', 239),\n",
       "             ('[La+3]', 240),\n",
       "             ('[Pt-2]', 241),\n",
       "             ('[N@@]', 242),\n",
       "             ('[PH3+]', 243),\n",
       "             ('[N@]', 244),\n",
       "             ('[Si+4]', 245),\n",
       "             ('[Sr+2]', 246),\n",
       "             ('[Al+]', 247),\n",
       "             ('[Pb]', 248),\n",
       "             ('[SeH]', 249),\n",
       "             ('[Si-]', 250),\n",
       "             ('[V+5]', 251),\n",
       "             ('[Y+3]', 252),\n",
       "             ('[Re]', 253),\n",
       "             ('[Ru+]', 254),\n",
       "             ('[Sm]', 255),\n",
       "             ('*', 256),\n",
       "             ('[3H]', 257),\n",
       "             ('[NH2]', 258),\n",
       "             ('[Ag-]', 259),\n",
       "             ('[13CH3]', 260),\n",
       "             ('[OH+]', 261),\n",
       "             ('[Ru+3]', 262),\n",
       "             ('[OH]', 263),\n",
       "             ('[Gd+3]', 264),\n",
       "             ('[13CH2]', 265),\n",
       "             ('[In+3]', 266),\n",
       "             ('[Si@@]', 267),\n",
       "             ('[Si@]', 268),\n",
       "             ('[Ti+2]', 269),\n",
       "             ('[Sn+]', 270),\n",
       "             ('[Cl+2]', 271),\n",
       "             ('[AlH-]', 272),\n",
       "             ('[Pd-2]', 273),\n",
       "             ('[SnH3]', 274),\n",
       "             ('[B+3]', 275),\n",
       "             ('[Cu-2]', 276),\n",
       "             ('[Nd+3]', 277),\n",
       "             ('[Pb+3]', 278),\n",
       "             ('[13cH]', 279),\n",
       "             ('[Fe-4]', 280),\n",
       "             ('[Ga]', 281),\n",
       "             ('[Sn+4]', 282),\n",
       "             ('[Hg+]', 283),\n",
       "             ('[11CH3]', 284),\n",
       "             ('[Hf]', 285),\n",
       "             ('[Pr]', 286),\n",
       "             ('[Y]', 287),\n",
       "             ('[S+2]', 288),\n",
       "             ('[Cd]', 289),\n",
       "             ('[Cr+6]', 290),\n",
       "             ('[Zr+3]', 291),\n",
       "             ('[Rh+]', 292),\n",
       "             ('[CH3]', 293),\n",
       "             ('[N-3]', 294),\n",
       "             ('[Hf+2]', 295),\n",
       "             ('[Th]', 296),\n",
       "             ('[Sb+3]', 297),\n",
       "             ('%14', 298),\n",
       "             ('[Cr+2]', 299),\n",
       "             ('[Ru+2]', 300),\n",
       "             ('[Hf+4]', 301),\n",
       "             ('[14C]', 302),\n",
       "             ('[Ta]', 303),\n",
       "             ('[Tl+]', 304),\n",
       "             ('[B+]', 305),\n",
       "             ('[Os+4]', 306),\n",
       "             ('[PdH2]', 307),\n",
       "             ('[Pd-]', 308),\n",
       "             ('[Cd+2]', 309),\n",
       "             ('[Co+3]', 310),\n",
       "             ('[S+4]', 311),\n",
       "             ('[Nb+5]', 312),\n",
       "             ('[123I]', 313),\n",
       "             ('[c+]', 314),\n",
       "             ('[Rb+]', 315),\n",
       "             ('[V+2]', 316),\n",
       "             ('[CH3+]', 317),\n",
       "             ('[Ag+2]', 318),\n",
       "             ('[cH+]', 319),\n",
       "             ('[Mn+3]', 320),\n",
       "             ('[Se-]', 321),\n",
       "             ('[As-]', 322),\n",
       "             ('[Eu+3]', 323),\n",
       "             ('[SH2]', 324),\n",
       "             ('[Sm+3]', 325),\n",
       "             ('[IH+]', 326),\n",
       "             ('%15', 327),\n",
       "             ('[OH3+]', 328),\n",
       "             ('[PH3]', 329),\n",
       "             ('[IH2+]', 330),\n",
       "             ('[SH2+]', 331),\n",
       "             ('[Ir+3]', 332),\n",
       "             ('[AlH3]', 333),\n",
       "             ('[Sc]', 334),\n",
       "             ('[Yb]', 335),\n",
       "             ('[15NH2]', 336),\n",
       "             ('[Lu]', 337),\n",
       "             ('[sH+]', 338),\n",
       "             ('[Gd]', 339),\n",
       "             ('[18F-]', 340),\n",
       "             ('[SH3+]', 341),\n",
       "             ('[SnH4]', 342),\n",
       "             ('[TeH]', 343),\n",
       "             ('[Si@@H]', 344),\n",
       "             ('[Ga+3]', 345),\n",
       "             ('[CaH2]', 346),\n",
       "             ('[Tl]', 347),\n",
       "             ('[Ta+5]', 348),\n",
       "             ('[GeH]', 349),\n",
       "             ('[Br+]', 350),\n",
       "             ('[Sr]', 351),\n",
       "             ('[Tl+3]', 352),\n",
       "             ('[Sm+2]', 353),\n",
       "             ('[PH5]', 354),\n",
       "             ('%16', 355),\n",
       "             ('[N@@+]', 356),\n",
       "             ('[Au+3]', 357),\n",
       "             ('[C-4]', 358),\n",
       "             ('[Nd]', 359),\n",
       "             ('[Ti+]', 360),\n",
       "             ('[IH]', 361),\n",
       "             ('[N@+]', 362),\n",
       "             ('[125I]', 363),\n",
       "             ('[Eu]', 364),\n",
       "             ('[Sn+3]', 365),\n",
       "             ('[Nb]', 366),\n",
       "             ('[Er+3]', 367),\n",
       "             ('[123I-]', 368),\n",
       "             ('[14c]', 369),\n",
       "             ('%17', 370),\n",
       "             ('[SnH2]', 371),\n",
       "             ('[YH]', 372),\n",
       "             ('[Sb+5]', 373),\n",
       "             ('[Pr+3]', 374),\n",
       "             ('[Ir+]', 375),\n",
       "             ('[N+3]', 376),\n",
       "             ('[AlH2]', 377),\n",
       "             ('[19F]', 378),\n",
       "             ('%18', 379),\n",
       "             ('[Tb]', 380),\n",
       "             ('[14CH]', 381),\n",
       "             ('[Mo+4]', 382),\n",
       "             ('[Si+]', 383),\n",
       "             ('[BH]', 384),\n",
       "             ('[Be]', 385),\n",
       "             ('[Rb]', 386),\n",
       "             ('[pH]', 387),\n",
       "             ('%19', 388),\n",
       "             ('%20', 389),\n",
       "             ('[Xe]', 390),\n",
       "             ('[Ir-]', 391),\n",
       "             ('[Be+2]', 392),\n",
       "             ('[C+4]', 393),\n",
       "             ('[RuH2]', 394),\n",
       "             ('[15NH]', 395),\n",
       "             ('[U+2]', 396),\n",
       "             ('[Au-]', 397),\n",
       "             ('%21', 398),\n",
       "             ('%22', 399),\n",
       "             ('[Au+]', 400),\n",
       "             ('[15n]', 401),\n",
       "             ('[Al+2]', 402),\n",
       "             ('[Tb+3]', 403),\n",
       "             ('[15N]', 404),\n",
       "             ('[V+3]', 405),\n",
       "             ('[W+6]', 406),\n",
       "             ('[14CH3]', 407),\n",
       "             ('[Cr+4]', 408),\n",
       "             ('[ClH+]', 409),\n",
       "             ('b', 410),\n",
       "             ('[Ti+6]', 411),\n",
       "             ('[Nd+]', 412),\n",
       "             ('[Zr+]', 413),\n",
       "             ('[PH2+]', 414),\n",
       "             ('[Fm]', 415),\n",
       "             ('[N@H+]', 416),\n",
       "             ('[RuH]', 417),\n",
       "             ('[Dy+3]', 418),\n",
       "             ('%23', 419),\n",
       "             ('[Hf+3]', 420),\n",
       "             ('[W+4]', 421),\n",
       "             ('[11C]', 422),\n",
       "             ('[13CH]', 423),\n",
       "             ('[Er]', 424),\n",
       "             ('[124I]', 425),\n",
       "             ('[LaH]', 426),\n",
       "             ('[F]', 427),\n",
       "             ('[siH]', 428),\n",
       "             ('[Ga+]', 429),\n",
       "             ('[Cm]', 430),\n",
       "             ('[GeH3]', 431),\n",
       "             ('[IH-]', 432),\n",
       "             ('[U+6]', 433),\n",
       "             ('[SeH+]', 434),\n",
       "             ('[32P]', 435),\n",
       "             ('[SeH-]', 436),\n",
       "             ('[Pt-]', 437),\n",
       "             ('[Ir+2]', 438),\n",
       "             ('[se+]', 439),\n",
       "             ('[U]', 440),\n",
       "             ('[F+]', 441),\n",
       "             ('[BH2]', 442),\n",
       "             ('[As+]', 443),\n",
       "             ('[Cf]', 444),\n",
       "             ('[ClH2+]', 445),\n",
       "             ('[Ni+]', 446),\n",
       "             ('[TeH3]', 447),\n",
       "             ('[SbH2]', 448),\n",
       "             ('[Ag+3]', 449),\n",
       "             ('%24', 450),\n",
       "             ('[18O]', 451),\n",
       "             ('[PH4]', 452),\n",
       "             ('[Os+2]', 453),\n",
       "             ('[Na-]', 454),\n",
       "             ('[Sb+2]', 455),\n",
       "             ('[V+4]', 456),\n",
       "             ('[Ho+3]', 457),\n",
       "             ('[68Ga]', 458),\n",
       "             ('[PH-]', 459),\n",
       "             ('[Bi+2]', 460),\n",
       "             ('[Ce+2]', 461),\n",
       "             ('[Pd+3]', 462),\n",
       "             ('[99Tc]', 463),\n",
       "             ('[13C@@H]', 464),\n",
       "             ('[Fe+6]', 465),\n",
       "             ('[c]', 466),\n",
       "             ('[GeH2]', 467),\n",
       "             ('[10B]', 468),\n",
       "             ('[Cu+3]', 469),\n",
       "             ('[Mo+2]', 470),\n",
       "             ('[Cr+]', 471),\n",
       "             ('[Pd+4]', 472),\n",
       "             ('[Dy]', 473),\n",
       "             ('[AsH]', 474),\n",
       "             ('[Ba+]', 475),\n",
       "             ('[SeH2]', 476),\n",
       "             ('[In+]', 477),\n",
       "             ('[TeH2]', 478),\n",
       "             ('[BrH+]', 479),\n",
       "             ('[14cH]', 480),\n",
       "             ('[W+]', 481),\n",
       "             ('[13C@H]', 482),\n",
       "             ('[AsH2]', 483),\n",
       "             ('[In+2]', 484),\n",
       "             ('[N+2]', 485),\n",
       "             ('[N@@H+]', 486),\n",
       "             ('[SbH]', 487),\n",
       "             ('[60Co]', 488),\n",
       "             ('[AsH4+]', 489),\n",
       "             ('[AsH3]', 490),\n",
       "             ('[18OH]', 491),\n",
       "             ('[Ru-2]', 492),\n",
       "             ('[Na-2]', 493),\n",
       "             ('[CuH2]', 494),\n",
       "             ('[31P]', 495),\n",
       "             ('[Ti+5]', 496),\n",
       "             ('[35S]', 497),\n",
       "             ('[P@@H]', 498),\n",
       "             ('[ArH]', 499),\n",
       "             ('[Co+]', 500),\n",
       "             ('[Zr-2]', 501),\n",
       "             ('[BH2-]', 502),\n",
       "             ('[131I]', 503),\n",
       "             ('[SH5]', 504),\n",
       "             ('[VH]', 505),\n",
       "             ('[B+2]', 506),\n",
       "             ('[Yb+2]', 507),\n",
       "             ('[14C@H]', 508),\n",
       "             ('[211At]', 509),\n",
       "             ('[NH3+2]', 510),\n",
       "             ('[IrH]', 511),\n",
       "             ('[IrH2]', 512),\n",
       "             ('[Rh-]', 513),\n",
       "             ('[Cr-]', 514),\n",
       "             ('[Sb+]', 515),\n",
       "             ('[Ni+3]', 516),\n",
       "             ('[TaH3]', 517),\n",
       "             ('[Tl+2]', 518),\n",
       "             ('[64Cu]', 519),\n",
       "             ('[Tc]', 520),\n",
       "             ('[Cd+]', 521),\n",
       "             ('[1H]', 522),\n",
       "             ('[15nH]', 523),\n",
       "             ('[AlH2+]', 524),\n",
       "             ('[FH+2]', 525),\n",
       "             ('[BiH3]', 526),\n",
       "             ('[Ru-]', 527),\n",
       "             ('[Mo+6]', 528),\n",
       "             ('[AsH+]', 529),\n",
       "             ('[BaH2]', 530),\n",
       "             ('[BaH]', 531),\n",
       "             ('[Fe+4]', 532),\n",
       "             ('[229Th]', 533),\n",
       "             ('[Th+4]', 534),\n",
       "             ('[As+3]', 535),\n",
       "             ('[NH+3]', 536),\n",
       "             ('[P@H]', 537),\n",
       "             ('[Li-]', 538),\n",
       "             ('[7NaH]', 539),\n",
       "             ('[Bi+]', 540),\n",
       "             ('[PtH+2]', 541),\n",
       "             ('[p-]', 542),\n",
       "             ('[Re+5]', 543),\n",
       "             ('[NiH]', 544),\n",
       "             ('[Ni-]', 545),\n",
       "             ('[Xe+]', 546),\n",
       "             ('[Ca+]', 547),\n",
       "             ('[11c]', 548),\n",
       "             ('[Rh+4]', 549),\n",
       "             ('[AcH]', 550),\n",
       "             ('[HeH]', 551),\n",
       "             ('[Sc+2]', 552),\n",
       "             ('[Mn+]', 553),\n",
       "             ('[UH]', 554),\n",
       "             ('[14CH2]', 555),\n",
       "             ('[SiH4+]', 556),\n",
       "             ('[18OH2]', 557),\n",
       "             ('[Ac-]', 558),\n",
       "             ('[Re+4]', 559),\n",
       "             ('[118Sn]', 560),\n",
       "             ('[153Sm]', 561),\n",
       "             ('[P+2]', 562),\n",
       "             ('[9CH]', 563),\n",
       "             ('[9CH3]', 564),\n",
       "             ('[Y-]', 565),\n",
       "             ('[NiH2]', 566),\n",
       "             ('[Si+2]', 567),\n",
       "             ('[Mn+6]', 568),\n",
       "             ('[ZrH2]', 569),\n",
       "             ('[C-2]', 570),\n",
       "             ('[Bi+5]', 571),\n",
       "             ('[24NaH]', 572),\n",
       "             ('[Fr]', 573),\n",
       "             ('[15CH]', 574),\n",
       "             ('[Se+]', 575),\n",
       "             ('[At]', 576),\n",
       "             ('[P-3]', 577),\n",
       "             ('[124I-]', 578),\n",
       "             ('[CuH2-]', 579),\n",
       "             ('[Nb+4]', 580),\n",
       "             ('[Nb+3]', 581),\n",
       "             ('[MgH]', 582),\n",
       "             ('[Ir+4]', 583),\n",
       "             ('[67Ga+3]', 584),\n",
       "             ('[67Ga]', 585),\n",
       "             ('[13N]', 586),\n",
       "             ('[15OH2]', 587),\n",
       "             ('[2NH]', 588),\n",
       "             ('[Ho]', 589),\n",
       "             ('[Cn]', 590)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a3aa04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94914a335ea440afabb9500aab386440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9926543 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode_smiles(sample):\n",
    "    #selfie = sf.encoder(sample['canonical_smiles'])\n",
    "    out_sample=tokenizer(sample['SMILES'], \n",
    "                                         max_length=128,\n",
    "                                          padding='max_length',\n",
    "                                          truncation=True) #,return_tensors = 'pt')\n",
    "    sample['input_ids']=out_sample['input_ids']\n",
    "    sample['attention_mask']=out_sample['attention_mask']\n",
    "    return sample\n",
    "dataset = dataset.map(encode_smiles)\n",
    "#dataset_dict['test'] = dataset_dict['test'].map(encode_smiles, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "795cf431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2868d9ce954ca399477eeba5b5bf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/15 shards):   0%|          | 0/9926543 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('encoded_pubchem10M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9ed8133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['SMILES', 'Count', '__index_level_0__', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 9926543\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d9af673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b8de6650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from collections import deque\n",
    "\n",
    "def rotate_smiles(smiles,num): #,canonical=True,isomericSmiles=True):\n",
    "    \"\"\"Perform a rotation of a SMILES string\n",
    "    must be RDKit sanitizable\"\"\"\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    ans = deque(list(range(m.GetNumAtoms())))\n",
    "    ans.rotate(num)\n",
    "    nm = Chem.RenumberAtoms(m,ans)\n",
    "    return Chem.MolToSmiles(nm, canonical=False)#, canonical=canonical, isomericSmiles=isomericSmiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8b54a9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [12, 16, 16, 121, 17, 16, 16, 18, 16, 20, 16, 16, 16, 17, 116, 16, 21, 16, 16, 21, 18, 17, 16, 17, 22, 19, 18, 36, 18, 16, 20, 13], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[12, 16, 17, 22, 19, 18, 17, 36, 18, 16, 20, 17, 116, 16, 21, 16, 16, 21, 18, 16, 16, 17, 121, 17, 16, 16, 18, 16, 16, 18, 16, 16, 20, 13]\n",
      "[12, 36, 16, 17, 16, 20, 17, 116, 16, 21, 16, 16, 21, 18, 16, 16, 17, 121, 17, 16, 16, 18, 16, 16, 18, 16, 16, 20, 18, 22, 19, 13]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(dataset[1]['SMILES']))\n",
    "print(tokenizer(rotate_smiles(dataset[1]['SMILES'],10000))['input_ids'])\n",
    "print(tokenizer(rotate_smiles(dataset[1]['SMILES'],2))['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "21aaad34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [12,\n",
       "  16,\n",
       "  16,\n",
       "  121,\n",
       "  17,\n",
       "  16,\n",
       "  16,\n",
       "  18,\n",
       "  16,\n",
       "  20,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  116,\n",
       "  16,\n",
       "  21,\n",
       "  16,\n",
       "  16,\n",
       "  21,\n",
       "  18,\n",
       "  17,\n",
       "  16,\n",
       "  17,\n",
       "  22,\n",
       "  19,\n",
       "  18,\n",
       "  36,\n",
       "  18,\n",
       "  16,\n",
       "  20,\n",
       "  13],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(tokenizer(dataset[1]['SMILES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73d19950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,   50,   33,   39,   21,  270,  263,   50,   13,   71],\n",
      "        [   0,  283,   21,  300,   12, 1064,  263,   55,  274,  271],\n",
      "        [   0,   51,   33,   39,   12,  278,   21,  268,   21,   17],\n",
      "        [   0,  291,   21,   39,  263,   55,   13,  291,   33,   39],\n",
      "        [   0,  298,   19,   39,   33,   39,   12,   19,   39,  263]])\n",
      "['N=C1NC(=N)c2cc3ccccc3cc21', 'COc1nn(CSP(=S)(OC)OC)c(=O)s1', 'O=C(Nc1ccccc1-c1ccc(Cl)cc1)c1cccnc1Cl', 'CN1C(=S)CN=C(c2ccccc2)c2cc(Cl)ccc21', 'CO/C=C(/C(=O)OC)c1ccccc1Oc1cc(Oc2ccccc2C#N)ncn1']\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "dataset = datasets.load_from_disk('/shared/tox21_hepg2_combined_split').with_format('torch')\n",
    "print(dataset['test'][0:5]['chem_input_ids'][:,:10])\n",
    "print(dataset['test'][0:5]['canonical_smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8ed309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f297c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "033ad0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9106])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig(torch.Tensor([2.320523262023926]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87cec9",
   "metadata": {},
   "source": [
    "# Fine tuning DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d142fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/efs-private/deepchem_data\n"
     ]
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "import os\n",
    "os.environ['DEEPCHEM_DATA_DIR']='/efs-private/deepchem_data'\n",
    "print(dc.utils.get_data_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9db95164",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_datasets = {\n",
    "    'QM7': dc.molnet.load_qm7,\n",
    "    #'QM7b': dc.molnet.load_qm7b,\n",
    "    #'QM8': dc.molnet.load_qm8,\n",
    "    'QM9': dc.molnet.load_qm9,\n",
    "    'ESOL': dc.molnet.load_delaney,\n",
    "    'FreeSolv': dc.molnet.load_freesolv,\n",
    "    'Lipophilicity': dc.molnet.load_lipo,\n",
    "    #'PCBA': dc.molnet.load_pcba,\n",
    "    #'MUV': dc.molnet.load_muv,\n",
    "    'HIV': dc.molnet.load_hiv,\n",
    "    #'PDBbind': dc.molnet.load_pdbbind,\n",
    "    'BACE': dc.molnet.load_bace_classification,\n",
    "    'BBBP': dc.molnet.load_bbbp,\n",
    "    #'Tox21': dc.molnet.load_tox21,\n",
    "    #'ToxCast': dc.molnet.load_toxcast,\n",
    "    #'SIDER': dc.molnet.load_sider,\n",
    "    #'ClinTox': dc.molnet.load_clintox,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "aaba2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mn_datasets_load = {k:v() for k,v in mn_datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25259a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/efs-private/chemjepa/chemjepa')\n",
    "from utils.smiles import absolute_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c17d45e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u0_atom']\n"
     ]
    }
   ],
   "source": [
    "dsn = 'QM7'\n",
    "iterator = mn_datasets_load[dsn][1][0].itersamples()\n",
    "tasks = mn_datasets_load[dsn][0]\n",
    "print(tasks)\n",
    "def get_samples(ds, idx=0):\n",
    "    iterator = ds[1][idx].itersamples()\n",
    "    while True:\n",
    "        try:\n",
    "            X, y, w, ids = next(iterator)\n",
    "            yield {'canonical_smiles':absolute_smiles(ids), 'targets':y}\n",
    "        except StopIteration as e:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c62bac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66addd284aaf4d09a5f9430a704a7f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5470 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68190a84674040e2b73db077d95fbdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dd34c0dbdf4a2db3fc9fbefdabc838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa04942a6be4af98b91fd9acf5069e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/105984 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454422952e6b4a03a9537a31fa37fd74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/13248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103075b9c01d4e83888724ce2d7c1e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/13248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESOL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff99f66c50f3401ebbe699c2f6e8fffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/902 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af67236e37b84738ad1af3aeb8696432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34638a545e4043b1867a764c60e1e06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreeSolv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05871073be574c27af5d15dcca66aebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/513 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59d5fffc66d48e4b669d68587a97042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa71df89181411aa52d89601079f17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/65 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lipophilicity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b074a93646a4406ad687677cab7b2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fd86bd412c42c2ab138e0ea03a8896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0b0fd830f0401aad135d1ecad935fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/420 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIV\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd0fcfa91e84247a82b80589f84f49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/32901 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f12a5a2529497fbb7284983fe51ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e968658e938748c8b71abf632ec6a56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BACE\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c958f505d04d1aafca8c7f0dadc075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6535856aa74f4afb819c2cd4227f7c98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/151 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf6b3514f4049668064e533ddbc36fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBBP\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b39e30e9444baabae8739cc3773491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1631 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e875cc1e0f2d4cc3a8ef29cc254e5d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5898b269fd49bbb6b0fd86786e3da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import os\n",
    "for k,v in mn_datasets_load.items():\n",
    "    print(k)\n",
    "    tasks = mn_datasets_load[k][0]\n",
    "    with open(os.path.join('/shared',f\"{k}_features.txt\"), 'w') as f:\n",
    "        f.writelines(tasks)\n",
    "    dsd = DatasetDict()\n",
    "    data = [x for x in iter(get_samples(mn_datasets_load[k], idx=0))]\n",
    "    dsd['train'] = Dataset.from_list(data)\n",
    "    data = [x for x in iter(get_samples(mn_datasets_load[k], idx=1))]\n",
    "    dsd['test'] = Dataset.from_list(data)\n",
    "    data = [x for x in iter(get_samples(mn_datasets_load[k], idx=2))]\n",
    "    dsd['val'] = Dataset.from_list(data)\n",
    "    dsd.save_to_disk(os.path.join('/shared',f\"{k}_dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "015e3f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['canonical_smiles', 'targets'],\n",
       "        num_rows: 1631\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['canonical_smiles', 'targets'],\n",
       "        num_rows: 204\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['canonical_smiles', 'targets'],\n",
       "        num_rows: 204\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86883610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dti",
   "language": "python",
   "name": "dti"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
